
import org.apache.spark.util.AccumulatorV2

case class YearPopulation(year: Int, population: Long)

class StateAccumulator extends AccumulatorV2[YearPopulation, YearPopulation] { 
      //declare the two variables one Int for year and Long for population
      private var year = 0 
      private var population:Long = 0L
 
      //return iszero if year and population are zero
      override def isZero: Boolean = year == 0 && population == 0L
 
      //copy accumulator and return a new accumulator
      override def copy(): StateAccumulator = {  
           val newAcc = new StateAccumulator  
           newAcc.year =     this.year  
           newAcc.population = this.population  
           newAcc 
       }

       //reset the year and population to zero 
       override def reset(): Unit = { year = 0 ; population = 0L }
 
       //add a value to the accumulator
       override def add(v: YearPopulation): Unit = { 
           year += v.year 
           population += v.population 
       }
 
       //merge two accumulators
       override def merge(other: AccumulatorV2[YearPopulation, YearPopulation]): Unit = {  
           other match {               
               case o: StateAccumulator => {     
                       year += o.year 
                       population += o.population    
               }    
               case _ =>   
           } 
        }

 
       //function called by Spark to access the value of accumulator
       override def value: YearPopulation = YearPopulation(year, population)
}

val statePopAcc = new StateAccumulator
sc.register(statePopAcc, "statePopAcc")

val statesPopulationRDD = sc.textFile("/data/statesPopulation.csv").filter(_.split(",")(0) != "State")
statesPopulationRDD.take(10)

statesPopulationRDD.map(x => {
	val toks = x.split(",")
	val year = toks(1).toInt
	val pop = toks(2).toLong
	statePopAcc.add(YearPopulation(year, pop))
	x
}).count

statePopAcc.value


